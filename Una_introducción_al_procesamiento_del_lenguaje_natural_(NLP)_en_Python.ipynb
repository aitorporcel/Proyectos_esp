{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Una introducción al procesamiento del lenguaje natural (NLP) en Python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wrIQCZ40zY6R"
      },
      "source": [
        "# Una introducción al procesamiento del lenguaje natural (NLP) en Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBQ1BNTjKSjy",
        "colab_type": "text"
      },
      "source": [
        "**\"A veces pienso que mi vida no es más que un conjunto de cursos de introducción a...\"**, así terminaba una clase sobre [docencia online](https://metadocencia.netlify.app/cursos/abc-online/intro-abc/), a la que asistí hace unas semanas. \n",
        "Después de varios días de seguir con esa frase en mente, abracé la idea y decidí animarme a escribir este breve texto de \"Introducción al procesamiento del lenguaje natural en Python\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPZ70iLZKSj0",
        "colab_type": "text"
      },
      "source": [
        "La idea es entonces dar una primera aproximación al tema en español, ya que la mayoría de los textos sobre el mismo se encuentran en inglés. Este es mi primer texto sobre programación, así que probablemente me avergüence de él dentro de unos meses, pero como dice el pensador contemporáneo [\"Jake the dog\"](https://www.youtube.com/watch?v=smgQiGABQMs):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-muTjbjOKSj1",
        "colab_type": "text"
      },
      "source": [
        "![Jake the Dog](https://pbs.twimg.com/media/ChezoMMUkAAVy26?format=jpg&name=small)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MsrgrttKSj2",
        "colab_type": "text"
      },
      "source": [
        "A lo largo de este texto vamos a analizar los títulos de los posts de la página [\"HackerNews\"](https://news.ycombinator.com/) (una comunidad donde los usuarios suben sus artículos y otros pueden votarlos) e intentar predecir el número de votos que recibirán, dependiendo de las palabras utilizadas. Los pasos que vamos a seguir se podrían resumir de la siguiente manera:\n",
        "\n",
        "1.   Importación e inspección inicial de la base de datos.\n",
        "2.   Muestreo aleatorio de la base de datos.\n",
        "3.   Implementación del modelo de \"bolsa de palabras\".\n",
        "4.   Implementación del modelo de regresión para predecir el número de puntos del post.\n",
        "\n",
        "Una primera duda que nos puede venir a la mente podría ser ¿qué es el procesamiento del lenguaje natural? Vamos a intentar esbozar una explicación fácil.\n",
        "\n",
        "Cuando intentamos aprender un idioma nuevo tenemos que aprender nuevos significados de palabras, nuevas reglas gramaticales, nuevas pronunciaciones, etc. La primera clase de idiomas típicamente se basa en saludos y conversaciones simples con la idea de que, poco a poco, vayamos incorporando el significado de cada término y adoptemos lentamente la nueva gramática. Por esta razón empezamos tomando notas y traduciendo cada palabra a nuestra lengua materna. De manera análoga nosotros tenemos que \"enseñarle\" a la computadora cómo es nuestro idioma, qué reglas usamos y traducir nuestras palabras al \"idioma\" de las computadoras, que se basa en 0s y 1s (o más bien en existencia o ausencia de pulsos eléctricos). **En resumen podríamos decir que el procesamiento del lenguaje natural consiste en enseñarle a las computadoras a interpretar, entender y manipular el lenguaje humano.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cWIofw_4zgP4"
      },
      "source": [
        "Empecemos con el primer paso del proyecto, la **importación e inspección inicial de la base de datos**. Los datos que vamos a utilizar son publicaciones realizadas por los usuarios de HackerNews entre 2006 y 2015. El mismo fue obtenido por Arnaud Drizard utilizando la API de la página y puede encontrarse en el siguiente [repositorio de Github](https://github.com/arnauddri/hn). De los archivos que se encuentran en el repositorio sólo trabajaremos con stories.csv (que pesa 171.MB aproximadamente) y que según la documentación tiene las siguientes columnas:\n",
        "\n",
        "* id\n",
        "* created_at\n",
        "* created_at_i\n",
        "* author\n",
        "* points\n",
        "* url_hostname\n",
        "* num_comments\n",
        "* title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3e_1QrU72pg8"
      },
      "source": [
        "Inicialmente importamos pandas, cargamos la base de datos e indicamos los nombres de las columnas (ya que el archivo no tiene títulos):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4texBqfKSj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "submissions = pd.read_csv(\"stories.csv\", header = None,\n",
        "                          names = [\"id\", \"created_at\", \"created_at_i\", \"author\", \"points\",\n",
        "                                   \"url_hostname\", \"num_comments\", \"title\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAmCCv5JKSj_",
        "colab_type": "text"
      },
      "source": [
        "Ahora exploramos la estructura del Dataframe para ver cómo está compuesto en detalle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q4vMEDjKSkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1e3b71a6-937f-4263-e696-c04afd16d29e"
      },
      "source": [
        "submissions.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>created_at_i</th>\n",
              "      <th>author</th>\n",
              "      <th>points</th>\n",
              "      <th>url_hostname</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9079978</td>\n",
              "      <td>2015-02-20T11:29:58.000Z</td>\n",
              "      <td>1424431798</td>\n",
              "      <td>Immortalin</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Ask HN: Simple SaaS as first Golang web app?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9079983</td>\n",
              "      <td>2015-02-20T11:34:22.000Z</td>\n",
              "      <td>1424432062</td>\n",
              "      <td>Rutger24s</td>\n",
              "      <td>1</td>\n",
              "      <td>startupjuncture.com</td>\n",
              "      <td>0</td>\n",
              "      <td>24sessions: live business advice over video-chat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9079986</td>\n",
              "      <td>2015-02-20T11:35:32.000Z</td>\n",
              "      <td>1424432132</td>\n",
              "      <td>AndrewDucker</td>\n",
              "      <td>3</td>\n",
              "      <td>blog.erratasec.com</td>\n",
              "      <td>0</td>\n",
              "      <td>Some notes on SuperFish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9079988</td>\n",
              "      <td>2015-02-20T11:36:18.000Z</td>\n",
              "      <td>1424432178</td>\n",
              "      <td>davidiach</td>\n",
              "      <td>1</td>\n",
              "      <td>twitter.com</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple Watch models could contain 29.16g of gold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9080000</td>\n",
              "      <td>2015-02-20T11:41:06.000Z</td>\n",
              "      <td>1424432466</td>\n",
              "      <td>CiaranR</td>\n",
              "      <td>1</td>\n",
              "      <td>phpconference.co.uk</td>\n",
              "      <td>0</td>\n",
              "      <td>PHP UK Conference Diversity Scholarship Programme</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                              title\n",
              "0  9079978  ...       Ask HN: Simple SaaS as first Golang web app?\n",
              "1  9079983  ...   24sessions: live business advice over video-chat\n",
              "2  9079986  ...                            Some notes on SuperFish\n",
              "3  9079988  ...    Apple Watch models could contain 29.16g of gold\n",
              "4  9080000  ...  PHP UK Conference Diversity Scholarship Programme\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw7Zn-FkKSkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e30ed53b-39fa-45dd-eb64-0efeba81fb34"
      },
      "source": [
        "submissions.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1553934 entries, 0 to 1553933\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count    Dtype \n",
            "---  ------        --------------    ----- \n",
            " 0   id            1553934 non-null  int64 \n",
            " 1   created_at    1553934 non-null  object\n",
            " 2   created_at_i  1553934 non-null  int64 \n",
            " 3   author        1553934 non-null  object\n",
            " 4   points        1553934 non-null  int64 \n",
            " 5   url_hostname  1459195 non-null  object\n",
            " 6   num_comments  1553934 non-null  int64 \n",
            " 7   title         1550600 non-null  object\n",
            "dtypes: int64(4), object(4)\n",
            "memory usage: 94.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9afNhO1KSkK",
        "colab_type": "text"
      },
      "source": [
        "Como podemos ver la base de datos está compuesta por más de un millón y medio de filas, como este texto sólo tiene un fin didáctico vamos proceder al segundo paso que es el **muestreo aleatorio de la base de datos**, que consistirá en tomar 6000 filas al azar para continuar con nuestro trabajo. Para el muestreo aleatorio vamos a usar un random_state de 1. La idea de esto es lograr que el proceso sea repetible y no especular repitiendo el muestreo hasta que obtengamos un resultado que favorezca a nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KNjGU2VKSkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submissions = submissions.sample(6000, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELHzxkq2KSkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b9098185-5086-403a-f036-4bc5032acfef"
      },
      "source": [
        "submissions.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6000 entries, 404493 to 826011\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            6000 non-null   int64 \n",
            " 1   created_at    6000 non-null   object\n",
            " 2   created_at_i  6000 non-null   int64 \n",
            " 3   author        6000 non-null   object\n",
            " 4   points        6000 non-null   int64 \n",
            " 5   url_hostname  5631 non-null   object\n",
            " 6   num_comments  6000 non-null   int64 \n",
            " 7   title         5991 non-null   object\n",
            "dtypes: int64(4), object(4)\n",
            "memory usage: 421.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a19eejQEKSkS",
        "colab_type": "text"
      },
      "source": [
        "Como podemos ver redujimos la base de datos a sólo 6000 entradas. Como próximo paso vamos a descartar algunas de las columnas de la base de datos, por ahora sólo nos quedaremos con:\n",
        "\n",
        "* created_at\n",
        "* points\n",
        "* url_hostname\n",
        "* title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4pJFIvOKSkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submissions = submissions.drop([\"id\", \"created_at_i\", \"author\", \"num_comments\"], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxAqBMuSKSkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f5354d9b-97e9-4000-b4f6-4d0a101daf73"
      },
      "source": [
        "submissions.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>points</th>\n",
              "      <th>url_hostname</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>404493</th>\n",
              "      <td>2013-09-26T12:11:48Z</td>\n",
              "      <td>4</td>\n",
              "      <td>youtube.com</td>\n",
              "      <td>Bill Gates interview at Harvard (2013)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435421</th>\n",
              "      <td>2009-05-08T14:36:28Z</td>\n",
              "      <td>2</td>\n",
              "      <td>news.bbc.co.uk</td>\n",
              "      <td>Google boss won't quit Apple job</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1207322</th>\n",
              "      <td>2011-02-15T18:44:58Z</td>\n",
              "      <td>1</td>\n",
              "      <td>n-rhman.com</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756837</th>\n",
              "      <td>2012-07-23T03:07:44Z</td>\n",
              "      <td>93</td>\n",
              "      <td>spectrum.ieee.org</td>\n",
              "      <td>Why Bad Jobs-or No Jobs-Happen to Good Workers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>639885</th>\n",
              "      <td>2012-12-19T19:50:57Z</td>\n",
              "      <td>2</td>\n",
              "      <td>charlespetzold.com</td>\n",
              "      <td>First-Person Shooter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   created_at  ...                                           title\n",
              "404493   2013-09-26T12:11:48Z  ...          Bill Gates interview at Harvard (2013)\n",
              "1435421  2009-05-08T14:36:28Z  ...                Google boss won't quit Apple job\n",
              "1207322  2011-02-15T18:44:58Z  ...                                                \n",
              "756837   2012-07-23T03:07:44Z  ...  Why Bad Jobs-or No Jobs-Happen to Good Workers\n",
              "639885   2012-12-19T19:50:57Z  ...                            First-Person Shooter\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWIb6t2PKSkY",
        "colab_type": "text"
      },
      "source": [
        "Para finalizar esta etapa de limpieza de datos vamos a descartar aquellas filas a las que les falta información, con el fin de que no afecten nuestro futuro modelo de predicción, incluyendo aquellos casos en los que no se incluye el título."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4WEIY6xKSkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submissions = submissions.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JUVT92lKSkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submissions = submissions.drop(submissions[submissions[\"title\"] == \" \"].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBsRzI9RKSke",
        "colab_type": "text"
      },
      "source": [
        "Finalmente reiniciamos el índice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SDFoHY4KSkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submissions = submissions.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVj7x4xeKSkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "89a5a00e-1852-4ad6-b77e-0773d9b374f1"
      },
      "source": [
        "submissions.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5619 entries, 0 to 5618\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   index         5619 non-null   int64 \n",
            " 1   created_at    5619 non-null   object\n",
            " 2   points        5619 non-null   int64 \n",
            " 3   url_hostname  5619 non-null   object\n",
            " 4   title         5619 non-null   object\n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 219.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g13WFJXz3UX9"
      },
      "source": [
        "Como dijimos anteriormente, las computadoras no \"hablan\" nuestro mismo idioma, por lo que vamos a necesitar \"traducirlo\" a su idioma. Para hacer esto vamos a convertir cada título en su representación numérica.\n",
        "\n",
        "Como indicamos en el tercer paso del procedimiento a seguir, el modelo que vamos a utilizar es el de \"bolsa de palabras\" (bag of words en inglés), el cual representa cada pieza de texto como un vector numérico indicando el número de veces que una palabra se repite en una oración.\n",
        "\n",
        "N° oración | hace | hoy | demasiado |mucho | frio | en | buenos | aires | para | andar | bicleta |\n",
        "--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "1 | 1 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | 0|\n",
        "2 | 1 | 1 | 1 | 0 | 1 | 2 | 1 | 1 | 1 | 1 | 1|\n",
        "\n",
        "El primer paso para crear una bolsa de palabras es tokenizar, lo que consiste en descomponer cada oración en palabras independientes.\n",
        "\n",
        "Por ejemplo podemos tokenizar:\n",
        " \"Hace mucho frío en Buenos Aires\" y \"Hoy hace demasiado frío en Buenos Aires para andar en bicicleta\" como:\n",
        " \n",
        "1. [\"hace\", \"mucho\", \"frío\", \"en\", \"buenos\", \"aires\"]\n",
        "2. [\"hoy\", \"hace\", \"demasiado\", \"frío\", \"en\", \"buenos\", \"aires\", \"para\", \"andar\", \"en\", \"bicicleta\"]\n",
        "\n",
        "Para lograr esto vamos a dividir cada oración en una lista individual de tokens, utilizando al espacio como separador. Sin embargo, antes de dividir los títulos es importante que le indiquemos a la computadora que \"Aires\", \"aires\" y \"aires!\" se refieren a la misma palabra, por lo que vamos a preprocesar los títulos eliminando las puntuaciones y pasando todo a minúscula, antes de \"traducirlo\". En resumen vamos a:\n",
        "\n",
        "* Eliminar los signos de puntuación de los títulos (para esto vamos a hacer uso de expresiones regulares).\n",
        "* Pasar todas las palabras a minúscula.\n",
        "* Separar cada palabra y transformar los títulos en una lista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ07DzsMKSkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Primero eliminamos la puntuacion\n",
        "submissions[\"title\"] = submissions[\"title\"].str.replace(\"[^0-9a-zA-Z ]+\",\" \")\n",
        "\n",
        "#Luego pasamos todo a minuscula\n",
        "submissions[\"title\"] = submissions[\"title\"].str.lower()\n",
        "\n",
        "#finalmente separamos cada palabra por los espacios y generamos una nueva columna\n",
        "submissions[\"tokenized_headlines\"] = submissions[\"title\"].str.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1rupqSN2isK",
        "colab_type": "text"
      },
      "source": [
        "*Nota sobre expresiones regulares*: Por si no están muy familiarizados con las expresiones regulares, lo que hicimos fue indicarle a la función que detecte todos los valores que no sean alfanuméricos ni espacios. El ^ niega todo lo que está entre corchetes, es decir que le estamos pidiendo a la computadora que busque y reemplace todos los valores que **NO** estén entre A-Z, ni entre a-z (para considerar mayúsculas y minúsculas), ni entre 0-9 (para considerar números). Luego agregamos a la lista de excluidos un espacio y fuera del corchete colocamos un + para indicar que repita esta condición una o más veces. En la segunda mitad de la función le indicamos que todos los caracteres que cumplan con esa condición (es decir que no estén incluidos en la lista de los **NO**) sean reemplazados por espacios “ “, ya que después lo usaremos como separador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niCp5iMvKSkp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "985161db-8fb2-47fc-c279-ee406166103c"
      },
      "source": [
        "submissions.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>created_at</th>\n",
              "      <th>points</th>\n",
              "      <th>url_hostname</th>\n",
              "      <th>title</th>\n",
              "      <th>tokenized_headlines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>404493</td>\n",
              "      <td>2013-09-26T12:11:48Z</td>\n",
              "      <td>4</td>\n",
              "      <td>youtube.com</td>\n",
              "      <td>bill gates interview at harvard  2013</td>\n",
              "      <td>[bill, gates, interview, at, harvard, 2013]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1435421</td>\n",
              "      <td>2009-05-08T14:36:28Z</td>\n",
              "      <td>2</td>\n",
              "      <td>news.bbc.co.uk</td>\n",
              "      <td>google boss won t quit apple job</td>\n",
              "      <td>[google, boss, won, t, quit, apple, job]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>756837</td>\n",
              "      <td>2012-07-23T03:07:44Z</td>\n",
              "      <td>93</td>\n",
              "      <td>spectrum.ieee.org</td>\n",
              "      <td>why bad jobs or no jobs happen to good workers</td>\n",
              "      <td>[why, bad, jobs, or, no, jobs, happen, to, goo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>639885</td>\n",
              "      <td>2012-12-19T19:50:57Z</td>\n",
              "      <td>2</td>\n",
              "      <td>charlespetzold.com</td>\n",
              "      <td>first person shooter</td>\n",
              "      <td>[first, person, shooter]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1164449</td>\n",
              "      <td>2011-04-15T20:26:31Z</td>\n",
              "      <td>5</td>\n",
              "      <td>whitehouse.gov</td>\n",
              "      <td>obama releases strategy for trusted identities...</td>\n",
              "      <td>[obama, releases, strategy, for, trusted, iden...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  ...                                tokenized_headlines\n",
              "0   404493  ...        [bill, gates, interview, at, harvard, 2013]\n",
              "1  1435421  ...           [google, boss, won, t, quit, apple, job]\n",
              "2   756837  ...  [why, bad, jobs, or, no, jobs, happen, to, goo...\n",
              "3   639885  ...                           [first, person, shooter]\n",
              "4  1164449  ...  [obama, releases, strategy, for, trusted, iden...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PZi7ZXmjEPxy"
      },
      "source": [
        "Ahora que ya tenemos nuestros tokens, podemos comenzar a convertir las oraciones en sus representaciones numéricas. Primero vamos a obtener todas las palabras únicas de los títulos. Luego vamos a crear una matriz y asignar esas palabras como nombres de columna, inicializando todos los valores en cero.\n",
        "En este caso sólo utilizaremos palabras que se repitan más de una vez, ya que incluir palabras con una única aparición le brinda poca información al modelo y le introduce ruido innecesario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WQMGzjzKSkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_tokens = set()\n",
        "single_tokens = set()\n",
        "\n",
        "def analyze_tokens(list):\n",
        "    \"\"\"Toma una lista y divide en tokens unicos (single_tokens) y tokens unicos con más de una repeticion (unique_tokens)\n",
        "    \n",
        "    Args:\n",
        "        lista = toma una lista de tokens\n",
        "        \n",
        "    Returns:\n",
        "        None = se incorpora en los sets externos\n",
        "    \"\"\"\n",
        "    for token in list:\n",
        "        if token in single_tokens:\n",
        "            unique_tokens.add(token)\n",
        "        else:\n",
        "            single_tokens.add(token)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdVak_XPKSkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_analyzed = submissions[\"tokenized_headlines\"].apply(analyze_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3WKGgNrKSky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "42689841-4bf1-4e51-b027-df8ecd18f328"
      },
      "source": [
        "print(\"Hay {} tokens unicos.\".format(len(single_tokens)))\n",
        "print(\"Hay {} tokens unicos que se repiten más de una vez.\".format(len(unique_tokens)))\n",
        "print(\"Solo un {:.2f}% de los tokens únicos se repite más de una vez.\".format((len(unique_tokens)/len(single_tokens))*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hay 10400 tokens unicos.\n",
            "Hay 4114 tokens unicos que se repiten más de una vez.\n",
            "Solo un 39.56% de los tokens únicos se repite más de una vez.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnaUvuCiKSk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Creamos una matriz con todos los tokens unicos como columnas\n",
        "counts = pd.DataFrame(0, index = np.arange(len(submissions[\"tokenized_headlines\"])),\n",
        "                      columns=unique_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mBkvmtVyF3MW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "2ae579fb-d3cd-494a-8fec-11a4a6744ae7"
      },
      "source": [
        "counts.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hijacking</th>\n",
              "      <th>original</th>\n",
              "      <th>adoption</th>\n",
              "      <th>interested</th>\n",
              "      <th>blocked</th>\n",
              "      <th>designs</th>\n",
              "      <th>won</th>\n",
              "      <th>ecommerce</th>\n",
              "      <th>principles</th>\n",
              "      <th>hairloss</th>\n",
              "      <th>english</th>\n",
              "      <th>demo</th>\n",
              "      <th>e3</th>\n",
              "      <th>paradox</th>\n",
              "      <th>off</th>\n",
              "      <th>adult</th>\n",
              "      <th>invented</th>\n",
              "      <th>cybersecurity</th>\n",
              "      <th>tevez</th>\n",
              "      <th>roles</th>\n",
              "      <th>ios</th>\n",
              "      <th>tv</th>\n",
              "      <th>ago</th>\n",
              "      <th>3</th>\n",
              "      <th>happiness</th>\n",
              "      <th>missing</th>\n",
              "      <th>billionaire</th>\n",
              "      <th>ipsum</th>\n",
              "      <th>99designs</th>\n",
              "      <th>feat</th>\n",
              "      <th>oem</th>\n",
              "      <th>thiel</th>\n",
              "      <th>50000</th>\n",
              "      <th>fixing</th>\n",
              "      <th>suggestions</th>\n",
              "      <th>leaves</th>\n",
              "      <th>kit</th>\n",
              "      <th>typography</th>\n",
              "      <th>ideas</th>\n",
              "      <th>investment</th>\n",
              "      <th>...</th>\n",
              "      <th>nike</th>\n",
              "      <th>scalability</th>\n",
              "      <th>em</th>\n",
              "      <th>720p</th>\n",
              "      <th>list</th>\n",
              "      <th>talk</th>\n",
              "      <th>lesson</th>\n",
              "      <th>successful</th>\n",
              "      <th>fitness</th>\n",
              "      <th>like</th>\n",
              "      <th>justice</th>\n",
              "      <th>authentication</th>\n",
              "      <th>halo</th>\n",
              "      <th>gaza</th>\n",
              "      <th>fights</th>\n",
              "      <th>ghost</th>\n",
              "      <th>comment</th>\n",
              "      <th>delete</th>\n",
              "      <th>joke</th>\n",
              "      <th>months</th>\n",
              "      <th>bans</th>\n",
              "      <th>canadian</th>\n",
              "      <th>client</th>\n",
              "      <th>yc</th>\n",
              "      <th>humanoid</th>\n",
              "      <th>action</th>\n",
              "      <th>protected</th>\n",
              "      <th>bet</th>\n",
              "      <th>space</th>\n",
              "      <th>exclusively</th>\n",
              "      <th>switch</th>\n",
              "      <th>children</th>\n",
              "      <th>downloads</th>\n",
              "      <th>managers</th>\n",
              "      <th>icrosofts</th>\n",
              "      <th>goliath</th>\n",
              "      <th>war</th>\n",
              "      <th>firefox</th>\n",
              "      <th>exist</th>\n",
              "      <th>coverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 4114 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   hijacking  original  adoption  interested  ...  war  firefox  exist  coverage\n",
              "0          0         0         0           0  ...    0        0      0         0\n",
              "1          0         0         0           0  ...    0        0      0         0\n",
              "2          0         0         0           0  ...    0        0      0         0\n",
              "3          0         0         0           0  ...    0        0      0         0\n",
              "4          0         0         0           0  ...    0        0      0         0\n",
              "\n",
              "[5 rows x 4114 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "42fCSWTDFPjl"
      },
      "source": [
        "Ahora que tenemos una matriz donde todos los valores son cero, vamos a llenarla con los valores correctos en cada celda. Esto involucra ir a cada conjunto de tokens e incrementar los contadores en la columna apropiada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7TCg8vbKSk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, tokens in enumerate(submissions[\"tokenized_headlines\"]):\n",
        "    for token in tokens:\n",
        "        if token in unique_tokens:\n",
        "            counts.loc[i,token] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FUXHD6qFGVVG"
      },
      "source": [
        "A esta altura tenemos más de 4000 columnas en nuestra matriz. El exceso de columnas también puede introducir ruido al modelo. Hay dos situaciones que pueden reducir la precisión de la predicción:\n",
        "* Palabras que ocurren pocas de veces pueden generar un sobreajuste ([overfitting](https://en.wikipedia.org/wiki/Overfitting)) porque el modelo no tiene suficiente información para decidir si son importantes. A su vez estas palabras probablemente se correlacionen distinto en el set de entrenamiento y en el de prueba.\n",
        "* Palabras que ocurren demasiadas veces también pueden generar problemas ya que ocurren prácticamente en todo título y no agregan información nueva que permita correlacionar con los votos positivos. En inglés estas palabras son llamadas [\"stopwords\"](https://en.wikipedia.org/wiki/Stop_words).\n",
        "\n",
        "Para reducir el número de palabras a analizar y permitir que el modelo de regresión realice mejores predicciones, vamos a remover las palabras que ocurren menos de 5 veces o más de 100 veces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dMTGVDiKSk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_counts = counts.sum()\n",
        "\n",
        "counts = counts[word_counts[(word_counts <= 100) & (word_counts >= 5)].index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kW7VRMjqHoPe"
      },
      "source": [
        "Ahora vamos a iniciar el 4to y último paso, la **implementación del modelo de regresión para predecir el número de puntos del post**. Para esto vamos a dividir la base de datos en dos sets y evaluar nuestro algoritmo, ajustándolo con los datos de entrenamiento y luego midiendo su eficiencia con los datos de prueba.\n",
        "\n",
        "Para esto vamos a usar la función train_test_split() de scikit-learn. Utilizaremos como parámetros un 20% para el tamaño del set de prueba y un estado aleatorio = 1. Al igual que con el muestreo aleatorio el objetivo de definirlo en 1 es lograr que el modelo sea reproducible.\n",
        "\n",
        "Los datos X_train y X_test van a contener los datos de entrada y y_train, y_test van a contener lo que queremos predecir (es decir, los votos positivos)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46uC9dIYKSlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(counts, submissions[\"points\"], test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2oGAkpsKyRE",
        "colab_type": "text"
      },
      "source": [
        "En este paso debemos seleccionar el modelo que utilizaremos para realizar las predicciones. Por una cuestión didáctica optaremos por un modelo simple como es la regresión lineal. Este modelo busca predecir el número de votos a través de una recta que minimice la distancia entre los votos reales y los predichos por el modelo como se puede ver a continuación:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYVpoyoNLmR_",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1200px-Linear_regression.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G76o5EUTLQ5g"
      },
      "source": [
        "Para esto haremos uso nuevamente de la librería scikit-learn y de la clase LinearRegression.\n",
        "\n",
        "Primero vamos a inicializar el modelo usando dicha clase. Luego vamos a usar el método fit() para entrenar el modelo con X_train y y_train. Finalmente vamos a predecir los resultados utilizando X_test.\n",
        "\n",
        "Cuando hacemos predicciones con un modelo de regresión lineal, el modelo asigna coeficientes a cada columna. Es decir que busca determinar cuáles palabras se correlacionan con más votos positivos y cuáles con menos. Encontrando estas correlaciones el modelo intentará predecir los votos positivos dependiendo de las palabras que se encuentren presente en el título."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsoNl7pbKSlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "clf = LinearRegression()\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qhig3h4UMQpl"
      },
      "source": [
        "Finalmente, utilizando nuestras predicciones vamos a calcular el error de nuestro modelo. Antes vamos a tener que elegir una métrica de error, en este caso vamos a trabajar con el error cuadratico medio (MSE) ya que penaliza los errores cuanto más lejos se encuentren del valor real, al elevarlos al cuadrado. Otra métrica de error posible a utilizar podría ser el MAE, la diferencia entre ambos excelede al presente texto, por lo que, para más información pueden ir al [siguiente artículo](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVq6uJ19KSlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse = ((y_test - predictions)**2).sum()/len(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fGdr0MIKSlJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d563621-4162-46c4-9d75-4d289d24c4bb"
      },
      "source": [
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2411.253069406075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVr7756JM67k"
      },
      "source": [
        "Conociendo el valor de MSE podemos compararlo con la distribución de los votos positivos. Para eso obtendremos la [media](https://es.wikipedia.org/wiki/Mediana_(estad%C3%ADstica)) y la [desviación estandar](https://es.wikipedia.org/wiki/Desviaci%C3%B3n_t%C3%ADpica) de los votos positivos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjFVvaykKSlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_upvotes = submissions[\"points\"].mean()\n",
        "std_upvotes = submissions[\"points\"].std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-cojmHDKSlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "34d11fe0-cbae-4d97-8c07-bf2930df3bba"
      },
      "source": [
        "print(\"La media de votos es: {:.2f}\".format(mean_upvotes))\n",
        "print(\"La desviación estándar de votos es: {:.2f}\".format(std_upvotes))\n",
        "print(\"La raíz del error cuadrático medio es: {:.2f}\".format(mse**0.5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La media de votos es: 10.28\n",
            "La desviación estándar de votos es: 39.82\n",
            "La raíz del error cuadrático medio es: 49.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2L3lnN9ENnYd"
      },
      "source": [
        "Como podemos ver la media de los votos positivos es de 10,28 y la desviación estandar es de 39,82. Si tomamos la raiz cuadrada del MSE vemos que es 49,10, lo cual puede interpretarse como que nuestro error promedio está a 49,10 votos positivos de distancia del valor real. Se trata de un valor bastante elevado pero a su vez esperable, ya que era poco probable que el número de votos siga una distribución lineal, como dijimos anteriormente la elección de este modelo perseguía un objetivo didáctico y no de precisión.\n",
        "\n",
        "Si bien vamos a finalizar el texto en este punto para evitar que se haga demasiado largo, podríamos tomar diferentes aproximaciones con el fin de mejorar la precisión del modelo, como por ejemplo:\n",
        "* Usar otros algoritmos de predicción más potentes como por ejemplo \"Random Forest\", que permitan captar la no linealidad entre las palabras utilizadas y los votos obtenidos.\n",
        "* Ampliar el número de muestras: esto debería reducir el error drásticamente ya que utilizar más información nos ayuda a que nuestro modelo pueda encontrar más ocurrencias en los sets de entrenamiento y de prueba, lo que mejorará las predicciones.\n",
        "* Agregar más características para analizar: por ejemplo incluir una variable que sea la longitud del título o la longitud promedio por palabra.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyuTZJ_d2mJ0",
        "colab_type": "text"
      },
      "source": [
        "**Conclusiones finales:** si bien el modelo no resultó muy preciso y requerirá ajustes para poder ser utilizado realmente, pudimos ver todo el proceso de importación de datos, limpieza, muestreo, análisis, vectorización del texto y predicción en una base de datos real. Finalmente lo que vamos a hacer es exportar los datos de la bolsa de palabras con el fin de analizarla en un futuro texto, utilizando un modelo que pueda captar la no linealidad en la relación entre las palabras utilizadas en el título y el número de votos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed4IlxBXGywn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts.to_csv(\"/counts.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v7vqPCKMVCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}